{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import utils\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from tqdm import tqdm\r\n",
    "import pickle\r\n",
    "import torch\r\n",
    "from typing import List, Tuple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class SkipGram(torch.nn.Module):\r\n",
    "    def __init__(self, vocab_size: int, emb_size: int):\r\n",
    "        super().__init__()\r\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\r\n",
    "        self.out = nn.Linear(emb_size, vocab_size)\r\n",
    "        self.vocab_size = vocab_size\r\n",
    "\r\n",
    "    def forward(self, word_id: int):\r\n",
    "        x = self.emb(word_id)\r\n",
    "        x = self.out(x)\r\n",
    "        return F.log_softmax(x, dim=-1)\r\n",
    "    \r\n",
    "    def get_emb(self, word_id: int):\r\n",
    "        return self.emb(word_id)\r\n",
    "\r\n",
    "\r\n",
    "def batched_data(processed_data: List[List[str]], batch_size: int, wdict: dict):\r\n",
    "    batch_x = []\r\n",
    "    batch_y = []\r\n",
    "    for doc in processed_data:\r\n",
    "        for i in range(len(doc)):\r\n",
    "            word = wdict[doc[i]]\r\n",
    "            for j in range(4):\r\n",
    "                idx = -2 + j\r\n",
    "                if idx >= 0:\r\n",
    "                    idx += 1\r\n",
    "                if i + idx >= 0 and i + idx < len(doc):\r\n",
    "                    context = wdict[doc[i + idx]]\r\n",
    "                    if len(batch_x) < batch_size:\r\n",
    "                        batch_x.append(word)\r\n",
    "                        batch_y.append(context)\r\n",
    "                    else:\r\n",
    "                        yield torch.tensor(batch_x), torch.tensor(batch_y)\r\n",
    "                        batch_x = []\r\n",
    "                        batch_y = []\r\n",
    "\r\n",
    "def create_wdict(processed_data: List[List[str]]) -> dict:\r\n",
    "    wdict = {}\r\n",
    "    for doc in processed_data:\r\n",
    "        for word in doc:\r\n",
    "            if word not in wdict:\r\n",
    "                wdict[word] = len(wdict)\r\n",
    "    return wdict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "processed_data = utils.import_smiles('data/HIV.csv', skiprow=True)\r\n",
    "wdict = create_wdict(processed_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 1000\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print(device)\r\n",
    "model = SkipGram(len(wdict), 300).to(device)\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \r\n",
    "\r\n",
    "\r\n",
    "for epoch in range(10):\r\n",
    "    with tqdm() as pbar:\r\n",
    "        for word, context in batched_data(processed_data, batch_size, wdict):\r\n",
    "            word = word.to(device)\r\n",
    "            context = context.to(device)\r\n",
    "            optimizer.zero_grad()\r\n",
    "            out = model(word)\r\n",
    "            loss = F.nll_loss(out, context)\r\n",
    "\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            pbar.update(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "6872it [00:14, 474.91it/s]\n",
      "6872it [00:12, 555.31it/s]\n",
      "6872it [00:12, 537.42it/s]\n",
      "6872it [00:13, 515.50it/s]\n",
      "6872it [00:12, 533.55it/s]\n",
      "6872it [00:12, 531.97it/s]\n",
      "6872it [00:12, 539.14it/s]\n",
      "6872it [00:13, 518.29it/s]\n",
      "6872it [00:12, 533.07it/s]\n",
      "6872it [00:12, 554.24it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "torch.save(model.state_dict(), 'models/emb.pt')\r\n",
    "with open('models/wdict.p', 'wb') as f:\r\n",
    "    pickle.dump(wdict, f)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('molnlp': conda)"
  },
  "interpreter": {
   "hash": "908b0ba9a178eea73af43abb00217a0aee98ad2ae4b0fcf81e35eb59597dfae8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}